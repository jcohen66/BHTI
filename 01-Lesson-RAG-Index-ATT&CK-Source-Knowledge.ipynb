{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: 1 - Indexing Data into a Vector Database and RAG with Langchain\n",
    "----------------------------------------------------------------------------\n",
    "In this lesson, we will demonstrate the process of indexing data into a vector database and using Langchain's Q&A chain to seamlessly implement the Retrieval Augmented Generation (RAG) flow for Knowledge Enhanced LLMs. We'll begin by downloading ATT&CK Enterprise data in STIX format using the attackcti Python library. Next, we'll extract all groups and techniques used by these groups to create markdown files simulating an Intel repository where threat intelligence analysts record notes about tracked threat actors. After loading and tokenizing these markdown files, we'll set them up in a FAISS database to generate embeddings. We will then apply a similarity search method to find relevant documents. Finally, we'll set the vector database as a retriever, initialize a retriever chain, and use it as a RAG chain with Langchain to automate retrieval and context addition, allowing the LLM to provide informed answers.\n",
    "\n",
    "## Objectives\n",
    "* Understand the process of indexing data into a vector database.\n",
    "* Learn how to set the vector database as a retriever and initialize a retriever chain for RAG.\n",
    "* Simulate an Intel repository using markdown files.\n",
    "* Generate embeddings and perform similarity searches to find relevant data.\n",
    "* Automate context addition to user prompts for improved LLM responses.\n",
    "\n",
    "## What this session covers:\n",
    "* Downloading and organizing ATT&CK Enterprise data using the attackcti Python library.\n",
    "* Extracting and converting group and technique data into markdown files.\n",
    "* Simulating an Intel repository with markdown files.\n",
    "* Loading, tokenizing, and embedding data in a FAISS database.\n",
    "* Performing similarity searches to find relevant documents.\n",
    "* Setting the vector database as a retriever.\n",
    "* Initializing and utilizing a retriever chain for RAG with Langchain.\n",
    "* Interacting with the LLM for enhanced, context-rich answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./venv/lib/python3.12/site-packages (1.54.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./venv/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in ./venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.7)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.1.139)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./venv/lib/python3.12/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain_openai in ./venv/lib/python3.12/site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./venv/lib/python3.12/site-packages (from langchain_openai) (0.3.15)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.52.0 in ./venv/lib/python3.12/site-packages (from langchain_openai) (1.54.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./venv/lib/python3.12/site-packages (from langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.1.139)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.66.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.12/site-packages (1.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.12/site-packages (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.12/site-packages (from pydantic) (4.12.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: attackcti in ./venv/lib/python3.12/site-packages (0.4.4)\n",
      "Requirement already satisfied: stix2 in ./venv/lib/python3.12/site-packages (from attackcti) (3.0.1)\n",
      "Requirement already satisfied: taxii2-client in ./venv/lib/python3.12/site-packages (from attackcti) (2.3.0)\n",
      "Requirement already satisfied: pydantic in ./venv/lib/python3.12/site-packages (from attackcti) (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic->attackcti) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic->attackcti) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.12/site-packages (from pydantic->attackcti) (4.12.2)\n",
      "Requirement already satisfied: pytz in ./venv/lib/python3.12/site-packages (from stix2->attackcti) (2024.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from stix2->attackcti) (2.32.3)\n",
      "Requirement already satisfied: simplejson in ./venv/lib/python3.12/site-packages (from stix2->attackcti) (3.19.3)\n",
      "Requirement already satisfied: stix2-patterns>=1.2.0 in ./venv/lib/python3.12/site-packages (from stix2->attackcti) (2.0.0)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.12/site-packages (from taxii2-client->attackcti) (1.16.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime~=4.9.0 in ./venv/lib/python3.12/site-packages (from stix2-patterns>=1.2.0->stix2->attackcti) (4.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->stix2->attackcti) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->stix2->attackcti) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->stix2->attackcti) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->stix2->attackcti) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: unstructured in ./venv/lib/python3.12/site-packages (0.16.4)\n",
      "Requirement already satisfied: chardet in ./venv/lib/python3.12/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in ./venv/lib/python3.12/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in ./venv/lib/python3.12/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in ./venv/lib/python3.12/site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.12/site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from unstructured) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./venv/lib/python3.12/site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in ./venv/lib/python3.12/site-packages (from unstructured) (2.14.0)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from unstructured) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in ./venv/lib/python3.12/site-packages (from unstructured) (2024.10.22)\n",
      "Requirement already satisfied: langdetect in ./venv/lib/python3.12/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in ./venv/lib/python3.12/site-packages (from unstructured) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in ./venv/lib/python3.12/site-packages (from unstructured) (3.10.1)\n",
      "Requirement already satisfied: backoff in ./venv/lib/python3.12/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.12/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in ./venv/lib/python3.12/site-packages (from unstructured) (0.27.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from unstructured) (1.16.0)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.12/site-packages (from unstructured) (4.66.6)\n",
      "Requirement already satisfied: psutil in ./venv/lib/python3.12/site-packages (from unstructured) (6.1.0)\n",
      "Requirement already satisfied: python-oxmsg in ./venv/lib/python3.12/site-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: html5lib in ./venv/lib/python3.12/site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->unstructured) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in ./venv/lib/python3.12/site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.12/site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk->unstructured) (2024.9.11)\n",
      "Requirement already satisfied: olefile in ./venv/lib/python3.12/site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->unstructured) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->unstructured) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->unstructured) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->unstructured) (2024.8.30)\n",
      "Requirement already satisfied: cryptography>=3.1 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (43.0.3)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (0.2.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (0.27.2)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.2 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (2.9.2)\n",
      "Requirement already satisfied: pypdf>=4.0 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./venv/lib/python3.12/site-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./venv/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (24.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<2.10.0,>=2.9.2->unstructured-client->unstructured) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: pycparser in ./venv/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: markdown in ./venv/lib/python3.12/site-packages (3.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tiktoken in ./venv/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./venv/lib/python3.12/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./venv/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain_huggingface in ./venv/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (0.26.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (0.3.15)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (3.2.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (0.20.2)\n",
      "Requirement already satisfied: transformers>=4.39.0 in ./venv/lib/python3.12/site-packages (from langchain_huggingface) (4.46.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.1.139)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in ./venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./venv/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.6)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.12/site-packages (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.12/site-packages (from jinja2) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install langchain_openai\n",
    "!pip install -qU langchain_community\n",
    "!pip install faiss-cpu\n",
    "!pip install pydantic\n",
    "!pip install attackcti\n",
    "!pip install unstructured\n",
    "!pip install markdown\n",
    "!pip install tiktoken\n",
    "!pip install langchain_huggingface\n",
    "!pip install jinja2\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Initial Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define a few variables\n",
    "current_directory = os.path.dirname(\"__file__\")\n",
    "data_directory = os.path.join(current_directory, \"data\")\n",
    "documents_directory = os.path.join(data_directory, \"documents\")\n",
    "templates_directory = os.path.join(current_directory, \"templates\")\n",
    "group_template = os.path.join(templates_directory, \"group.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download ATT&CK STIX Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded enterprise-attack.json to data/attack/v15.1\n",
      "Downloaded mobile-attack.json to data/attack/v15.1\n",
      "Downloaded ics-attack.json to data/attack/v15.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'enterprise': 'data/attack/v15.1/enterprise-attack.json',\n",
       " 'mobile': 'data/attack/v15.1/mobile-attack.json',\n",
       " 'ics': 'data/attack/v15.1/ics-attack.json'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from attackcti.utils.downloader import STIXDownloader\n",
    "\n",
    "stix20_downloader = STIXDownloader(download_dir=\"./data/attack\", stix_version=\"2.0\")\n",
    "\n",
    "stix20_downloader.download_all_domains(release=\"15.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'enterprise': 'data/attack/v15.1/enterprise-attack.json',\n",
       " 'mobile': 'data/attack/v15.1/mobile-attack.json',\n",
       " 'ics': 'data/attack/v15.1/ics-attack.json'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stix20_downloader.downloaded_file_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize ATT&CK Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attackcti import attack_client\n",
    "\n",
    "lift = attack_client(local_paths=stix20_downloader.downloaded_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Techniques Used by ATT&CK Groups\n",
    "Gettings technique STIX objects used by all groups accross all ATT&CK matrices.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'intrusion-set',\n",
       " 'id': 'intrusion-set--01e28736-2ffc-455b-9880-ed4d1407ae07',\n",
       " 'created_by_ref': 'identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5',\n",
       " 'created': '2021-01-06T17:46:35.134Z',\n",
       " 'modified': '2024-04-17T22:10:56.266Z',\n",
       " 'name': 'Indrik Spider',\n",
       " 'description': '[Indrik Spider](https://attack.mitre.org/groups/G0119) is a Russia-based cybercriminal group that has been active since at least 2014. [Indrik Spider](https://attack.mitre.org/groups/G0119) initially started with the [Dridex](https://attack.mitre.org/software/S0384) banking Trojan, and then by 2017 they began running ransomware operations using [BitPaymer](https://attack.mitre.org/software/S0570), [WastedLocker](https://attack.mitre.org/software/S0612), and Hades ransomware. Following U.S. sanctions and an indictment in 2019, [Indrik Spider](https://attack.mitre.org/groups/G0119) changed their tactics and diversified their toolset.(Citation: Crowdstrike Indrik November 2018)(Citation: Crowdstrike EvilCorp March 2021)(Citation: Treasury EvilCorp Dec 2019)',\n",
       " 'aliases': ['Indrik Spider', 'Evil Corp', 'Manatee Tempest', 'DEV-0243'],\n",
       " 'external_references': [{'source_name': 'mitre-attack',\n",
       "   'url': 'https://attack.mitre.org/groups/G0119',\n",
       "   'external_id': 'G0119'},\n",
       "  {'source_name': 'Evil Corp',\n",
       "   'description': '(Citation: Crowdstrike EvilCorp March 2021)(Citation: Treasury EvilCorp Dec 2019)'},\n",
       "  {'source_name': 'Manatee Tempest',\n",
       "   'description': '(Citation: Microsoft Threat Actor Naming July 2023)'},\n",
       "  {'source_name': 'DEV-0243',\n",
       "   'description': '(Citation: Microsoft Threat Actor Naming July 2023)'},\n",
       "  {'source_name': 'Crowdstrike Indrik November 2018',\n",
       "   'description': 'Frankoff, S., Hartley, B. (2018, November 14). Big Game Hunting: The Evolution of INDRIK SPIDER From Dridex Wire Fraud to BitPaymer Targeted Ransomware. Retrieved January 6, 2021.',\n",
       "   'url': 'https://www.crowdstrike.com/blog/big-game-hunting-the-evolution-of-indrik-spider-from-dridex-wire-fraud-to-bitpaymer-targeted-ransomware/'},\n",
       "  {'source_name': 'Microsoft Threat Actor Naming July 2023',\n",
       "   'description': 'Microsoft . (2023, July 12). How Microsoft names threat actors. Retrieved November 17, 2023.',\n",
       "   'url': 'https://learn.microsoft.com/en-us/microsoft-365/security/intelligence/microsoft-threat-actor-naming?view=o365-worldwide'},\n",
       "  {'source_name': 'Crowdstrike EvilCorp March 2021',\n",
       "   'description': 'Podlosky, A., Feeley, B. (2021, March 17). INDRIK SPIDER Supersedes WastedLocker with Hades Ransomware to Circumvent OFAC Sanctions. Retrieved September 15, 2021.',\n",
       "   'url': 'https://www.crowdstrike.com/blog/hades-ransomware-successor-to-indrik-spiders-wastedlocker/'},\n",
       "  {'source_name': 'Treasury EvilCorp Dec 2019',\n",
       "   'description': 'U.S. Department of Treasury. (2019, December 5). Treasury Sanctions Evil Corp, the Russia-Based Cybercriminal Group Behind Dridex Malware. Retrieved September 15, 2021.',\n",
       "   'url': 'https://home.treasury.gov/news/press-releases/sm845'}],\n",
       " 'object_marking_refs': ['marking-definition--fa42a846-8d90-4e51-bc29-71d5b4802168'],\n",
       " 'x_mitre_attack_spec_version': '3.2.0',\n",
       " 'x_mitre_contributors': ['Jennifer Kim Roman, CrowdStrike'],\n",
       " 'x_mitre_deprecated': False,\n",
       " 'x_mitre_domains': ['enterprise-attack'],\n",
       " 'x_mitre_modified_by_ref': 'identity--c78cb6e5-0c4b-4611-8297-d1b8b55e40b5',\n",
       " 'x_mitre_version': '4.0',\n",
       " 'technique_ref': 'attack-pattern--65f2d882-3f41-4d48-8a06-29af77ec9f90',\n",
       " 'relationship_description': '[Indrik Spider](https://attack.mitre.org/groups/G0119) used [Cobalt Strike](https://attack.mitre.org/software/S0154) to carry out credential dumping using ProcDump.(Citation: Symantec WastedLocker June 2020)',\n",
       " 'relationship_id': 'relationship--000aa4d0-315e-40d7-b2b6-76e91ecf0fe8',\n",
       " 'revoked': False,\n",
       " 'technique': 'LSASS Memory',\n",
       " 'technique_description': \"Adversaries may attempt to access credential material stored in the process memory of the Local Security Authority Subsystem Service (LSASS). After a user logs on, the system generates and stores a variety of credential materials in LSASS process memory. These credential materials can be harvested by an administrative user or SYSTEM and used to conduct [Lateral Movement](https://attack.mitre.org/tactics/TA0008) using [Use Alternate Authentication Material](https://attack.mitre.org/techniques/T1550).\\n\\nAs well as in-memory techniques, the LSASS process memory can be dumped from the target host and analyzed on a local system.\\n\\nFor example, on the target host use procdump:\\n\\n* <code>procdump -ma lsass.exe lsass_dump</code>\\n\\nLocally, mimikatz can be run using:\\n\\n* <code>sekurlsa::Minidump lsassdump.dmp</code>\\n* <code>sekurlsa::logonPasswords</code>\\n\\nBuilt-in Windows tools such as `comsvcs.dll` can also be used:\\n\\n* <code>rundll32.exe C:\\\\Windows\\\\System32\\\\comsvcs.dll MiniDump PID  lsass.dmp full</code>(Citation: Volexity Exchange Marauder March 2021)(Citation: Symantec Attacks Against Government Sector)\\n\\nSimilar to [Image File Execution Options Injection](https://attack.mitre.org/techniques/T1546/012), the silent process exit mechanism can be abused to create a memory dump of `lsass.exe` through Windows Error Reporting (`WerFault.exe`).(Citation: Deep Instinct LSASS)\\n\\nWindows Security Support Provider (SSP) DLLs are loaded into LSASS process at system start. Once loaded into the LSA, SSP DLLs have access to encrypted and plaintext passwords that are stored in Windows, such as any logged-on user's Domain password or smart card PINs. The SSP configuration is stored in two Registry keys: <code>HKLM\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Lsa\\\\Security Packages</code> and <code>HKLM\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\Lsa\\\\OSConfig\\\\Security Packages</code>. An adversary may modify these Registry keys to add new SSPs, which will be loaded the next time the system boots, or when the AddSecurityPackage Windows API function is called.(Citation: Graeber 2014)\\n\\nThe following SSPs can be used to access credentials:\\n\\n* Msv: Interactive logons, batch logons, and service logons are done through the MSV authentication package.\\n* Wdigest: The Digest Authentication protocol is designed for use with Hypertext Transfer Protocol (HTTP) and Simple Authentication Security Layer (SASL) exchanges.(Citation: TechNet Blogs Credential Protection)\\n* Kerberos: Preferred for mutual client-server domain authentication in Windows 2000 and later.\\n* CredSSP:  Provides SSO and Network Level Authentication for Remote Desktop Services.(Citation: TechNet Blogs Credential Protection)\\n\",\n",
       " 'tactic': [KillChainPhase(kill_chain_name='mitre-attack', phase_name='credential-access')],\n",
       " 'technique_id': 'T1003.001',\n",
       " 'technique_matrix': ['enterprise-attack'],\n",
       " 'platform': ['Windows'],\n",
       " 'data_sources': ['Process: Process Access',\n",
       "  'Windows Registry: Windows Registry Key Modification',\n",
       "  'Process: Process Creation',\n",
       "  'Process: OS API Execution',\n",
       "  'Logon Session: Logon Session Creation',\n",
       "  'Command: Command Execution',\n",
       "  'File: File Creation']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techniques_used_by_groups = lift.get_techniques_used_by_all_groups()\n",
    "techniques_used_by_groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG BEGINS!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Get Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ATT&CK Groups Markdown Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Creating markadown files for each group..\n",
      "  [>>] Creating markdown file for Indrik Spider..\n",
      "  [>>] Creating markdown file for LuminousMoth..\n",
      "  [>>] Creating markdown file for Wizard Spider..\n",
      "  [>>] Creating markdown file for Elderwood..\n",
      "  [>>] Creating markdown file for FIN7..\n",
      "  [>>] Creating markdown file for WIRTE..\n",
      "  [>>] Creating markdown file for Dragonfly..\n",
      "  [>>] Creating markdown file for OilRig..\n",
      "  [>>] Creating markdown file for Equation..\n",
      "  [>>] Creating markdown file for Fox Kitten..\n",
      "  [>>] Creating markdown file for Lazarus Group..\n",
      "  [>>] Creating markdown file for Aquatic Panda..\n",
      "  [>>] Creating markdown file for TA505..\n",
      "  [>>] Creating markdown file for Inception..\n",
      "  [>>] Creating markdown file for admin@338..\n",
      "  [>>] Creating markdown file for BlackTech..\n",
      "  [>>] Creating markdown file for Malteiro..\n",
      "  [>>] Creating markdown file for Earth Lusca..\n",
      "  [>>] Creating markdown file for Turla..\n",
      "  [>>] Creating markdown file for Suckfly..\n",
      "  [>>] Creating markdown file for TeamTNT..\n",
      "  [>>] Creating markdown file for FIN6..\n",
      "  [>>] Creating markdown file for Silence..\n",
      "  [>>] Creating markdown file for Patchwork..\n",
      "  [>>] Creating markdown file for APT28..\n",
      "  [>>] Creating markdown file for Aoqin Dragon..\n",
      "  [>>] Creating markdown file for Cinnamon Tempest..\n",
      "  [>>] Creating markdown file for HEXANE..\n",
      "  [>>] Creating markdown file for Darkhotel..\n",
      "  [>>] Creating markdown file for Ke3chang..\n",
      "  [>>] Creating markdown file for Leafminer..\n",
      "  [>>] Creating markdown file for Magic Hound..\n",
      "  [>>] Creating markdown file for APT29..\n",
      "  [>>] Creating markdown file for EXOTIC LILY..\n",
      "  [>>] Creating markdown file for Sandworm Team..\n",
      "  [>>] Creating markdown file for Cobalt Group..\n",
      "  [>>] Creating markdown file for Andariel..\n",
      "  [>>] Creating markdown file for HAFNIUM..\n",
      "  [>>] Creating markdown file for APT39..\n",
      "  [>>] Creating markdown file for MuddyWater..\n",
      "  [>>] Creating markdown file for APT38..\n",
      "  [>>] Creating markdown file for Volt Typhoon..\n",
      "  [>>] Creating markdown file for Transparent Tribe..\n",
      "  [>>] Creating markdown file for Ember Bear..\n",
      "  [>>] Creating markdown file for APT32..\n",
      "  [>>] Creating markdown file for BRONZE BUTLER..\n",
      "  [>>] Creating markdown file for POLONIUM..\n",
      "  [>>] Creating markdown file for APT5..\n",
      "  [>>] Creating markdown file for BackdoorDiplomacy..\n",
      "  [>>] Creating markdown file for Kimsuky..\n",
      "  [>>] Creating markdown file for Leviathan..\n",
      "  [>>] Creating markdown file for Ajax Security Team..\n",
      "  [>>] Creating markdown file for Akira..\n",
      "  [>>] Creating markdown file for Mustang Panda..\n",
      "  [>>] Creating markdown file for LAPSUS$..\n",
      "  [>>] Creating markdown file for Chimera..\n",
      "  [>>] Creating markdown file for TA2541..\n",
      "  [>>] Creating markdown file for ToddyCat..\n",
      "  [>>] Creating markdown file for BITTER..\n",
      "  [>>] Creating markdown file for RTM..\n",
      "  [>>] Creating markdown file for menuPass..\n",
      "  [>>] Creating markdown file for Tropic Trooper..\n",
      "  [>>] Creating markdown file for Mustard Tempest..\n",
      "  [>>] Creating markdown file for APT19..\n",
      "  [>>] Creating markdown file for Moses Staff..\n",
      "  [>>] Creating markdown file for Molerats..\n",
      "  [>>] Creating markdown file for Stealth Falcon..\n",
      "  [>>] Creating markdown file for DarkVishnya..\n",
      "  [>>] Creating markdown file for APT37..\n",
      "  [>>] Creating markdown file for Threat Group-1314..\n",
      "  [>>] Creating markdown file for APT41..\n",
      "  [>>] Creating markdown file for FIN13..\n",
      "  [>>] Creating markdown file for Group5..\n",
      "  [>>] Creating markdown file for PLATINUM..\n",
      "  [>>] Creating markdown file for GALLIUM..\n",
      "  [>>] Creating markdown file for FIN10..\n",
      "  [>>] Creating markdown file for Winnti Group..\n",
      "  [>>] Creating markdown file for FIN8..\n",
      "  [>>] Creating markdown file for Rocke..\n",
      "  [>>] Creating markdown file for Scattered Spider..\n",
      "  [>>] Creating markdown file for CURIUM..\n",
      "  [>>] Creating markdown file for Windigo..\n",
      "  [>>] Creating markdown file for Blue Mockingbird..\n",
      "  [>>] Creating markdown file for FIN4..\n",
      "  [>>] Creating markdown file for Gorgon Group..\n",
      "  [>>] Creating markdown file for Sidewinder..\n",
      "  [>>] Creating markdown file for Higaisa..\n",
      "  [>>] Creating markdown file for APT30..\n",
      "  [>>] Creating markdown file for Windshift..\n",
      "  [>>] Creating markdown file for Confucius..\n",
      "  [>>] Creating markdown file for Threat Group-3390..\n",
      "  [>>] Creating markdown file for Tonto Team..\n",
      "  [>>] Creating markdown file for Gamaredon Group..\n",
      "  [>>] Creating markdown file for Rancor..\n",
      "  [>>] Creating markdown file for TA551..\n",
      "  [>>] Creating markdown file for Axiom..\n",
      "  [>>] Creating markdown file for Dark Caracal..\n",
      "  [>>] Creating markdown file for Nomadic Octopus..\n",
      "  [>>] Creating markdown file for APT12..\n",
      "  [>>] Creating markdown file for APT3..\n",
      "  [>>] Creating markdown file for Putter Panda..\n",
      "  [>>] Creating markdown file for Metador..\n",
      "  [>>] Creating markdown file for TA459..\n",
      "  [>>] Creating markdown file for ZIRCONIUM..\n",
      "  [>>] Creating markdown file for APT1..\n",
      "  [>>] Creating markdown file for Naikon..\n",
      "  [>>] Creating markdown file for Sowbug..\n",
      "  [>>] Creating markdown file for Mofang..\n",
      "  [>>] Creating markdown file for Machete..\n",
      "  [>>] Creating markdown file for FIN5..\n",
      "  [>>] Creating markdown file for SideCopy..\n",
      "  [>>] Creating markdown file for APT33..\n",
      "  [>>] Creating markdown file for GOLD SOUTHFIELD..\n",
      "  [>>] Creating markdown file for Volatile Cedar..\n",
      "  [>>] Creating markdown file for Evilnum..\n",
      "  [>>] Creating markdown file for Cleaver..\n",
      "  [>>] Creating markdown file for TEMP.Veles..\n",
      "  [>>] Creating markdown file for DarkHydrus..\n",
      "  [>>] Creating markdown file for Whitefly..\n",
      "  [>>] Creating markdown file for Silent Librarian..\n",
      "  [>>] Creating markdown file for APT18..\n",
      "  [>>] Creating markdown file for Carbanak..\n",
      "  [>>] Creating markdown file for Orangeworm..\n",
      "  [>>] Creating markdown file for Deep Panda..\n",
      "  [>>] Creating markdown file for APT-C-36..\n",
      "  [>>] Creating markdown file for The White Company..\n",
      "  [>>] Creating markdown file for Poseidon Group..\n",
      "  [>>] Creating markdown file for LazyScripter..\n",
      "  [>>] Creating markdown file for Gallmaker..\n",
      "  [>>] Creating markdown file for MoustachedBouncer..\n",
      "  [>>] Creating markdown file for CopyKittens..\n",
      "  [>>] Creating markdown file for Thrip..\n",
      "  [>>] Creating markdown file for PROMETHIUM..\n",
      "  [>>] Creating markdown file for GCMAN..\n",
      "  [>>] Creating markdown file for Ferocious Kitten..\n",
      "  [>>] Creating markdown file for PittyTiger..\n",
      "  [>>] Creating markdown file for APT17..\n",
      "  [>>] Creating markdown file for BlackOasis..\n",
      "  [>>] Creating markdown file for IndigoZebra..\n",
      "  [>>] Creating markdown file for SilverTerrier..\n",
      "  [>>] Creating markdown file for Strider..\n",
      "  [>>] Creating markdown file for Scarlet Mimic..\n",
      "  [>>] Creating markdown file for APT16..\n",
      "  [>>] Creating markdown file for Moafee..\n",
      "  [>>] Creating markdown file for APT-C-23..\n",
      "  [>>] Creating markdown file for Bouncing Golf..\n",
      "  [>>] Creating markdown file for UNC788..\n",
      "  [>>] Creating markdown file for ALLANITE..\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from jinja2 import Template\n",
    "\n",
    "# Create Group docs\n",
    "all_groups = dict()\n",
    "for technique in techniques_used_by_groups:\n",
    "    if technique[\"id\"] not in all_groups:\n",
    "        group = dict()\n",
    "        group[\"group_name\"] = technique[\"name\"]\n",
    "        group[\"group_id\"] = technique[\"external_references\"][0][\"external_id\"]\n",
    "        group[\"created\"] = technique[\"created\"]\n",
    "        group[\"modified\"] = technique[\"modified\"]\n",
    "        group[\"description\"] = technique[\"description\"]\n",
    "        group[\"aliases\"] = technique[\"aliases\"]\n",
    "        if \"x_mitre_contributors\" in technique:\n",
    "            group[\"contributors\"] = technique[\"x_mitre_contributors\"]\n",
    "        group[\"techniques\"] = []\n",
    "        all_groups[technique[\"id\"]] = group\n",
    "    technique_used = dict()\n",
    "    technique_used[\"matrix\"] = technique[\"technique_matrix\"]\n",
    "    technique_used[\"domain\"] = technique[\"x_mitre_domains\"]\n",
    "    technique_used[\"platform\"] = technique[\"platform\"]\n",
    "    technique_used[\"tactics\"] = technique[\"tactic\"]\n",
    "    technique_used[\"technique_id\"] = technique[\"technique_id\"]\n",
    "    technique_used[\"technique_name\"] = technique[\"technique\"]\n",
    "    technique_used[\"use\"] = technique[\"relationship_description\"]\n",
    "    if \"data_sources\" in technique:\n",
    "        technique_used[\"data_sources\"] = technique[\"data_sources\"]\n",
    "    all_groups[technique[\"id\"]][\"techniques\"].append(technique_used)\n",
    "\n",
    "if not os.path.exists(documents_directory):\n",
    "    print(\"[+] Creating knowledge directory..\")\n",
    "    os.makedirs(documents_directory)\n",
    "\n",
    "print(\"[+] Creating markadown files for each group..\")\n",
    "markdown_template = Template(open(group_template).read())\n",
    "for key in list(all_groups.keys()):\n",
    "    group = all_groups[key]\n",
    "    print(\"  [>>] Creating markdown file for {}..\".format(group[\"group_name\"]))\n",
    "    group_for_render = copy.deepcopy(group)\n",
    "    markdown = markdown_template.render(\n",
    "        metadata=group_for_render,\n",
    "        group_name=group[\"group_name\"],\n",
    "        group_id=group[\"group_id\"],\n",
    "    )\n",
    "    file_name = (group[\"group_name\"]).replace(\" \", \"_\")\n",
    "    open(f\"{documents_directory}/{file_name}.md\", encoding=\"utf-8\", mode=\"w\").write(\n",
    "        markdown\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Index Source Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading Group markdown files..\n",
      " [*] Loading Deep_Panda.md\n",
      " [*] Loading Aoqin_Dragon.md\n",
      " [*] Loading Poseidon_Group.md\n",
      " [*] Loading Whitefly.md\n",
      " [*] Loading Magic_Hound.md\n",
      " [*] Loading APT-C-23.md\n",
      " [*] Loading Earth_Lusca.md\n",
      " [*] Loading Windigo.md\n",
      " [*] Loading Cleaver.md\n",
      " [*] Loading FIN7.md\n",
      " [*] Loading APT12.md\n",
      " [*] Loading FIN13.md\n",
      " [*] Loading Transparent_Tribe.md\n",
      " [*] Loading APT32.md\n",
      " [*] Loading Confucius.md\n",
      " [*] Loading Tropic_Trooper.md\n",
      " [*] Loading UNC788.md\n",
      " [*] Loading BlackOasis.md\n",
      " [*] Loading The_White_Company.md\n",
      " [*] Loading BlackTech.md\n",
      " [*] Loading Axiom.md\n",
      " [*] Loading Chimera.md\n",
      " [*] Loading OilRig.md\n",
      " [*] Loading APT16.md\n",
      " [*] Loading IndigoZebra.md\n",
      " [*] Loading Leviathan.md\n",
      " [*] Loading APT33.md\n",
      " [*] Loading Windshift.md\n",
      " [*] Loading Sowbug.md\n",
      " [*] Loading Tonto_Team.md\n",
      " [*] Loading DarkHydrus.md\n",
      " [*] Loading APT-C-36.md\n",
      " [*] Loading PittyTiger.md\n",
      " [*] Loading APT17.md\n",
      " [*] Loading Strider.md\n",
      " [*] Loading APT37.md\n",
      " [*] Loading Ke3chang.md\n",
      " [*] Loading Gorgon_Group.md\n",
      " [*] Loading FIN6.md\n",
      " [*] Loading Aquatic_Panda.md\n",
      " [*] Loading Threat_Group-3390.md\n",
      " [*] Loading Rancor.md\n",
      " [*] Loading Cinnamon_Tempest.md\n",
      " [*] Loading HAFNIUM.md\n",
      " [*] Loading APT5.md\n",
      " [*] Loading APT18.md\n",
      " [*] Loading WIRTE.md\n",
      " [*] Loading Scarlet_Mimic.md\n",
      " [*] Loading Sandworm_Team.md\n",
      " [*] Loading Mustang_Panda.md\n",
      " [*] Loading Ajax_Security_Team.md\n",
      " [*] Loading Leafminer.md\n",
      " [*] Loading TA505.md\n",
      " [*] Loading Ember_Bear.md\n",
      " [*] Loading RTM.md\n",
      " [*] Loading APT38.md\n",
      " [*] Loading LazyScripter.md\n",
      " [*] Loading APT28.md\n",
      " [*] Loading APT1.md\n",
      " [*] Loading POLONIUM.md\n",
      " [*] Loading Carbanak.md\n",
      " [*] Loading DarkVishnya.md\n",
      " [*] Loading Gamaredon_Group.md\n",
      " [*] Loading LuminousMoth.md\n",
      " [*] Loading ZIRCONIUM.md\n",
      " [*] Loading Blue_Mockingbird.md\n",
      " [*] Loading Turla.md\n",
      " [*] Loading APT39.md\n",
      " [*] Loading Gallmaker.md\n",
      " [*] Loading APT29.md\n",
      " [*] Loading Orangeworm.md\n",
      " [*] Loading FIN8.md\n",
      " [*] Loading TA551.md\n",
      " [*] Loading Silent_Librarian.md\n",
      " [*] Loading Group5.md\n",
      " [*] Loading APT19.md\n",
      " [*] Loading BackdoorDiplomacy.md\n",
      " [*] Loading Putter_Panda.md\n",
      " [*] Loading Lazarus_Group.md\n",
      " [*] Loading MuddyWater.md\n",
      " [*] Loading Threat_Group-1314.md\n",
      " [*] Loading Suckfly.md\n",
      " [*] Loading Bouncing_Golf.md\n",
      " [*] Loading TEMP.Veles.md\n",
      " [*] Loading Andariel.md\n",
      " [*] Loading Evilnum.md\n",
      " [*] Loading Akira.md\n",
      " [*] Loading Mofang.md\n",
      " [*] Loading Dark_Caracal.md\n",
      " [*] Loading ToddyCat.md\n",
      " [*] Loading PLATINUM.md\n",
      " [*] Loading APT3.md\n",
      " [*] Loading Mustard_Tempest.md\n",
      " [*] Loading Indrik_Spider.md\n",
      " [*] Loading Wizard_Spider.md\n",
      " [*] Loading HEXANE.md\n",
      " [*] Loading BITTER.md\n",
      " [*] Loading GOLD_SOUTHFIELD.md\n",
      " [*] Loading Metador.md\n",
      " [*] Loading SilverTerrier.md\n",
      " [*] Loading Moafee.md\n",
      " [*] Loading admin@338.md\n",
      " [*] Loading Cobalt_Group.md\n",
      " [*] Loading CopyKittens.md\n",
      " [*] Loading Moses_Staff.md\n",
      " [*] Loading Winnti_Group.md\n",
      " [*] Loading Silence.md\n",
      " [*] Loading Malteiro.md\n",
      " [*] Loading Sidewinder.md\n",
      " [*] Loading Naikon.md\n",
      " [*] Loading Darkhotel.md\n",
      " [*] Loading CURIUM.md\n",
      " [*] Loading Ferocious_Kitten.md\n",
      " [*] Loading Dragonfly.md\n",
      " [*] Loading MoustachedBouncer.md\n",
      " [*] Loading Stealth_Falcon.md\n",
      " [*] Loading GALLIUM.md\n",
      " [*] Loading APT30.md\n",
      " [*] Loading Inception.md\n",
      " [*] Loading TeamTNT.md\n",
      " [*] Loading Rocke.md\n",
      " [*] Loading Kimsuky.md\n",
      " [*] Loading Molerats.md\n",
      " [*] Loading Volt_Typhoon.md\n",
      " [*] Loading Machete.md\n",
      " [*] Loading SideCopy.md\n",
      " [*] Loading PROMETHIUM.md\n",
      " [*] Loading GCMAN.md\n",
      " [*] Loading LAPSUS$.md\n",
      " [*] Loading Thrip.md\n",
      " [*] Loading FIN5.md\n",
      " [*] Loading TA459.md\n",
      " [*] Loading APT41.md\n",
      " [*] Loading Volatile_Cedar.md\n",
      " [*] Loading menuPass.md\n",
      " [*] Loading Fox_Kitten.md\n",
      " [*] Loading EXOTIC_LILY.md\n",
      " [*] Loading Scattered_Spider.md\n",
      " [*] Loading ALLANITE.md\n",
      " [*] Loading Higaisa.md\n",
      " [*] Loading FIN4.md\n",
      " [*] Loading FIN10.md\n",
      " [*] Loading Nomadic_Octopus.md\n",
      " [*] Loading BRONZE_BUTLER.md\n",
      " [*] Loading TA2541.md\n",
      " [*] Loading Elderwood.md\n",
      " [*] Loading Equation.md\n",
      " [*] Loading Patchwork.md\n",
      "[+] Number of .md documents processed: 148\n"
     ]
    }
   ],
   "source": [
    "# variables\n",
    "group_files = glob.glob(os.path.join(documents_directory, \"*.md\"))\n",
    "\n",
    "# Loading Markdown files\n",
    "md_docs = []\n",
    "print(\"[+] Loading Group markdown files..\")\n",
    "for group in group_files:\n",
    "    print(f\" [*] Loading {os.path.basename(group)}\")\n",
    "    loader = UnstructuredMarkdownLoader(group)\n",
    "    md_docs.extend(loader.load())\n",
    "\n",
    "print(f\"[+] Number of .md documents processed: {len(md_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check a doc page content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Panda - G0009\n",
      "\n",
      "Created: 2017-05-31T21:31:49.412Z\n",
      "\n",
      "Modified: 2022-07-20T20:10:29.593Z\n",
      "\n",
      "Contributors: Andrew Smith, @jakx_\n",
      "\n",
      "Aliases\n",
      "\n",
      "Deep Panda,Shell Crew,WebMasters,KungFu Kittens,PinkPanther,Black Vine\n",
      "\n",
      "Description\n",
      "\n",
      "Deep Panda is a suspected Chinese threat group known to target many industries, including government, defense, financial, and telecommunications. (Citation: Alperovitch 2014) The intrusion into healthcare company Anthem has been attributed to Deep Panda. (Citation: ThreatConnect Anthem) This group is also known as Shell Crew, WebMasters, KungFu Kittens, and PinkPanther. (Citation: RSA Shell Crew) Deep Panda also appears to be known as Black Vine based on the attribution of both group names to the Anthem intrusion. (Citation: Symantec Black Vine) Some analysts track Deep Panda and APT19 as the same group, but it is unclear from open source information if the groups are the same. (Citation: ICIT China's Espionage Jul 2016)\n",
      "\n",
      "Techniques Used\n",
      "\n",
      "Matrix Domain Platform Technique ID Technique Name Use ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1057 Process Discovery Deep Panda uses the Microsoft Tasklist utility to list processes running on systems.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1018 Remote System Discovery Deep Panda has used ping to identify other machines of interest.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Linux,Windows,macOS,Network T1505.003 Web Shell Deep Panda uses Web shells on publicly accessible Web servers to access victim networks.(Citation: CrowdStrike Deep Panda Web Shells) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1027.005 Indicator Removal from Tools Deep Panda has updated and modified its malware, resulting in different hash values that evade detection.(Citation: Symantec Black Vine) ['enterprise-attack'] enterprise-attack Windows T1218.010 Regsvr32 Deep Panda has used regsvr32.exe to execute a server variant of Derusbi in victim networks.(Citation: RSA Shell Crew) ['enterprise-attack'] enterprise-attack macOS,Windows,Linux T1564.003 Hidden Window Deep Panda has used -w hidden to conceal PowerShell windows by setting the WindowStyle parameter to hidden. (Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1059.001 PowerShell Deep Panda has used PowerShell scripts to download and execute programs in memory, without writing to disk.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1546.008 Accessibility Features Deep Panda has used the sticky-keys technique to bypass the RDP login screen on remote systems during intrusions.(Citation: RSA Shell Crew) ['enterprise-attack'] enterprise-attack Windows T1047 Windows Management Instrumentation The Deep Panda group is known to utilize WMI for lateral movement.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1021.002 SMB/Windows Admin Shares Deep Panda uses net.exe to connect to network shares using net use commands with compromised credentials.(Citation: Alperovitch 2014)\n"
     ]
    }
   ],
   "source": [
    "print(md_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Split Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use langchain text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursively split by character\n",
    "# This text splitter is the recommended one for generic text.\n",
    "# It is parameterized by a list of characters. It tries to split on them in\n",
    "# order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
    "# This has the effect of trying to keep all paragraphs (and then sentences, and then words)\n",
    "# together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text, disallowed_special=()  # To disable this check for all special tokens\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Initializing RecursiveCharacterTextSplitter..\n"
     ]
    }
   ],
   "source": [
    "# Chunking Text\n",
    "print(\"[+] Initializing RecursiveCharacterTextSplitter..\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,  # number of tokens overlap between chunks\n",
    "    add_start_index=True,  # the character index at which each split Document starts within the initial Document is preserved\n",
    "    length_function=tiktoken_len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Splitting documents in chunks..\n",
      "[+] Number of documents: 148\n",
      "[+] Number of chunks: 398\n"
     ]
    }
   ],
   "source": [
    "print(\"[+] Splitting documents in chunks..\")\n",
    "chunks = text_splitter.split_documents(md_docs)\n",
    "\n",
    "print(f\"[+] Number of documents: {len(md_docs)}\")\n",
    "print(f\"[+] Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Deep Panda - G0009\n",
      "\n",
      "Created: 2017-05-31T21:31:49.412Z\n",
      "\n",
      "Modified: 2022-07-20T20:10:29.593Z\n",
      "\n",
      "Contributors: Andrew Smith, @jakx_\n",
      "\n",
      "Aliases\n",
      "\n",
      "Deep Panda,Shell Crew,WebMasters,KungFu Kittens,PinkPanther,Black Vine\n",
      "\n",
      "Description\n",
      "\n",
      "Deep Panda is a suspected Chinese threat group known to target many industries, including government, defense, financial, and telecommunications. (Citation: Alperovitch 2014) The intrusion into healthcare company Anthem has been attributed to Deep Panda. (Citation: ThreatConnect Anthem) This group is also known as Shell Crew, WebMasters, KungFu Kittens, and PinkPanther. (Citation: RSA Shell Crew) Deep Panda also appears to be known as Black Vine based on the attribution of both group names to the Anthem intrusion. (Citation: Symantec Black Vine) Some analysts track Deep Panda and APT19 as the same group, but it is unclear from open source information if the groups are the same. (Citation: ICIT China's Espionage Jul 2016)\n",
      "\n",
      "Techniques Used\n",
      "\n",
      "Matrix Domain Platform Technique ID Technique Name Use ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1057 Process Discovery Deep Panda uses the Microsoft Tasklist utility to list processes running on systems.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1018 Remote System Discovery Deep Panda has used ping to identify other machines of interest.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Linux,Windows,macOS,Network T1505.003 Web Shell Deep Panda uses Web shells on publicly accessible Web servers to access victim networks.(Citation: CrowdStrike Deep Panda Web Shells) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1027.005 Indicator Removal from Tools Deep Panda has updated and modified its malware, resulting in different hash values that evade detection.(Citation: Symantec Black Vine) ['enterprise-attack'] enterprise-attack Windows T1218.010 Regsvr32 Deep Panda has used regsvr32.exe to execute a server variant of Derusbi in victim networks.(Citation: RSA Shell Crew) ['enterprise-attack'] enterprise-attack macOS,Windows,Linux T1564.003 Hidden Window Deep Panda has used -w hidden to conceal PowerShell windows by setting the WindowStyle parameter to hidden. (Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1059.001 PowerShell Deep Panda has used PowerShell scripts to download and execute programs in memory, without writing to disk.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1546.008 Accessibility Features Deep Panda has used the sticky-keys technique to bypass the RDP login screen on remote systems during intrusions.(Citation: RSA Shell Crew) ['enterprise-attack'] enterprise-attack Windows T1047 Windows Management Instrumentation The Deep Panda group is known to utilize WMI for lateral movement.(Citation: Alperovitch 2014) ['enterprise-attack'] enterprise-attack Windows T1021.002 SMB/Windows Admin Shares Deep Panda uses net.exe to connect to network shares using net use commands with compromised credentials.(Citation: Alperovitch 2014)' metadata={'source': 'data/documents/Deep_Panda.md', 'start_index': 0}\n",
      "page_content='Aoqin Dragon - G1007\n",
      "\n",
      "Created: 2022-07-14T14:32:47.582Z\n",
      "\n",
      "Modified: 2022-10-24T18:50:40.179Z\n",
      "\n",
      "Contributors: Hiroki Nagahama, NEC Corporation,Pooja Natarajan, NEC Corporation India,Manikantan Srinivasan, NEC Corporation India\n",
      "\n",
      "Aliases\n",
      "\n",
      "Aoqin Dragon\n",
      "\n",
      "Description\n",
      "\n",
      "Aoqin Dragon is a suspected Chinese cyber espionage threat group that has been active since at least 2013. Aoqin Dragon has primarily targeted government, education, and telecommunication organizations in Australia, Cambodia, Hong Kong, Singapore, and Vietnam. Security researchers noted a potential association between Aoqin Dragon and UNC94, based on malware, infrastructure, and targets.(Citation: SentinelOne Aoqin Dragon June 2022)\n",
      "\n",
      "Techniques Used\n",
      "\n",
      "Matrix Domain Platform Technique ID Technique Name Use ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1204.002 Malicious File Aoqin Dragon has lured victims into opening weaponized documents, fake external drives, and fake antivirus to execute malicious payloads.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1570 Lateral Tool Transfer Aoqin Dragon has spread malware in target networks by copying modules to folders masquerading as removable devices.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack Windows T1091 Replication Through Removable Media Aoqin Dragon has used a dropper that employs a worm infection strategy using a removable device to breach a secure network environment.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack macOS,Windows,Linux T1027.002 Software Packing Aoqin Dragon has used the Themida packer to obfuscate malicious payloads.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack PRE T1587.001 Malware Aoqin Dragon has used custom malware, including Mongall and Heyoka Backdoor , in their operations.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1083 File and Directory Discovery Aoqin Dragon has run scripts to identify file formats including Microsoft Word.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Containers T1036.005 Match Legitimate Name or Location Aoqin Dragon has used fake icons including antivirus and external drives to disguise malicious payloads.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack PRE T1588.002 Tool Aoqin Dragon obtained the Heyoka open source exfiltration tool and subsequently modified it for their operations.(Citation: SentinelOne Aoqin Dragon June 2022) ['enterprise-attack'] enterprise-attack Linux,Windows,macOS T1203 Exploitation for Client Execution Aoqin Dragon has exploited CVE-2012-0158 and CVE-2010-3333 for execution against targeted systems.(Citation: SentinelOne Aoqin Dragon June 2022)' metadata={'source': 'data/documents/Aoqin_Dragon.md', 'start_index': 0}\n",
      "page_content='Poseidon Group - G0033\n",
      "\n",
      "Created: 2017-05-31T21:32:04.179Z\n",
      "\n",
      "Modified: 2020-03-18T20:25:54.945Z\n",
      "\n",
      "Contributors:\n",
      "\n",
      "Aliases\n",
      "\n",
      "Poseidon Group\n",
      "\n",
      "Description\n",
      "\n",
      "Poseidon Group is a Portuguese-speaking threat group that has been active since at least 2005. The group has a history of using information exfiltrated from victims to blackmail victim companies into contracting the Poseidon Group as a security firm. (Citation: Kaspersky Poseidon Group)\n",
      "\n",
      "Techniques Used\n",
      "\n",
      "Matrix Domain Platform Technique ID Technique Name Use ['enterprise-attack'] enterprise-attack Windows,IaaS,Linux,macOS,Network T1049 System Network Connections Discovery Poseidon Group obtains and saves information about victim network interfaces and addresses.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Windows,Linux,macOS T1003 OS Credential Dumping Poseidon Group conducts credential dumping on victims, with a focus on obtaining credentials belonging to domain and database servers.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Windows,macOS,Linux T1007 System Service Discovery After compromising a victim, Poseidon Group discovers all running services.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1087.002 Domain Account Poseidon Group searches for administrator accounts on both the local victim machine and the network.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1087.001 Local Account Poseidon Group searches for administrator accounts on both the local victim machine and the network.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1057 Process Discovery After compromising a victim, Poseidon Group lists all running processes.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Containers T1036.005 Match Legitimate Name or Location Poseidon Group tools attempt to spoof anti-virus processes as a means of self-defense.(Citation: Kaspersky Poseidon Group) ['enterprise-attack'] enterprise-attack Windows T1059.001 PowerShell The Poseidon Group 's Information Gathering Tool (IGT) includes PowerShell components.(Citation: Kaspersky Poseidon Group)' metadata={'source': 'data/documents/Poseidon_Group.md', 'start_index': 0}\n"
     ]
    }
   ],
   "source": [
    "print(chunks[0])\n",
    "print(chunks[1])\n",
    "print(chunks[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Embed Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS  # , DistanceStrategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the embeddings function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathancohen/Code/Python/BHTI/BHTI/venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# If you want to define the OpenAI embeddings function\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# If you want to define an open-source embedding function\n",
    "embeddings_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "# Equivalent to SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create or load database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/v0.2/docs/integrations/vectorstores/faiss/\n",
    "from langchain_community.vectorstores.faiss import DistanceStrategy\n",
    "\n",
    "db_dir = \"data/faiss/faiss_index\"\n",
    "\n",
    "# Check if database directory exists\n",
    "if os.path.exists(db_dir):\n",
    "    # Load database from disk\n",
    "    db = FAISS.load_local(\n",
    "        folder_path=db_dir,\n",
    "        embeddings=embeddings_function,\n",
    "        distance_strategy=DistanceStrategy.COSINE,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "else:\n",
    "    # With OpenAI Embeddings\n",
    "    # db = FAISS.from_documents(chunks, OpenAIEmbeddings())\n",
    "\n",
    "    # Create a new database\n",
    "    db = FAISS.from_documents(\n",
    "        chunks, embedding=embeddings_function, distance_strategy=DistanceStrategy.COSINE\n",
    "    )\n",
    "    # Sabe database to disk\n",
    "    db.save_local(\"data/faiss/faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ask a question directly to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query it\n",
    "query = \"What threat actor sends text messages over social media to their targets?\"\n",
    "relevant_docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\documents\\\\Magic_Hound.md', 'start_index': 20568}, page_content='as well as messaging services (such as WhatsApp) to spearphish victims.(Citation: SecureWorks Mia Ash July 2017)(Citation: Microsoft Phosphorus Mar 2019)(Citation: ClearSky Kittens Back 3 August 2020) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows T1560.001 Archive via Utility Magic Hound has used gzip to archive dumped LSASS process memory and RAR to stage and compress local folders.(Citation: FireEye APT35 2018)(Citation: DFIR Report APT35 ProxyShell March 2022)(Citation: DFIR Phosphorus November 2021) [\\'enterprise-attack\\'] enterprise-attack PRE T1585.001 Social Media Accounts Magic Hound has created fake LinkedIn and other social media accounts to contact targets and convince them--through messages and voice communications--to open malicious links.(Citation: ClearSky Kittens Back 3 August 2020) [\\'enterprise-attack\\'] enterprise-attack macOS,Windows,Linux T1564.003 Hidden Window Magic Hound malware has a function to determine whether the C2 server wishes to execute the newly dropped file in a hidden window.(Citation: Unit 42 Magic Hound Feb 2017) [\\'enterprise-attack\\'] enterprise-attack Windows,Office 365,IaaS,Linux,macOS,Containers,Network T1562 Impair Defenses Magic Hound has disabled LSA protection on compromised hosts using \"reg\" add HKLM\\\\SYSTEM\\\\CurrentControlSet\\\\Control\\\\LSA /v RunAsPPL /t REG_DWORD /d 0 /f .(Citation: DFIR Report APT35 ProxyShell March 2022) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows,Network T1005 Data from Local System Magic Hound has used a web shell to exfiltrate a ZIP file containing a dump of LSASS memory on a compromised machine.(Citation: DFIR Report APT35 ProxyShell March 2022)(Citation: DFIR Phosphorus November 2021) [\\'enterprise-attack\\'] enterprise-attack Windows T1047 Windows Management Instrumentation Magic Hound has used a tool to run cmd /c wmic computersystem get domain for discovery.(Citation: DFIR Report APT35 ProxyShell March 2022) [\\'enterprise-attack\\'] enterprise-attack PRE T1583.006 Web Services Magic Hound has acquired Amazon S3 buckets to use in C2.(Citation: Check Point APT35 CharmPower January 2022) [\\'enterprise-attack\\'] enterprise-attack Windows,Linux,macOS,SaaS T1189 Drive-by Compromise Magic Hound has conducted watering-hole attacks through media and magazine websites.(Citation: ClearSky Kittens Back 3 August 2020)'),\n",
       " Document(metadata={'source': 'data\\\\documents\\\\Threat_Group-3390.md', 'start_index': 0}, page_content='Threat Group-3390 - G0027\\n\\nCreated: 2017-05-31T21:31:58.518Z\\n\\nModified: 2024-04-10T22:33:06.500Z\\n\\nContributors: Daniyal Naeem, BT Security,Kyaw Pyiyt Htet, @KyawPyiytHtet\\n\\nAliases\\n\\nThreat Group-3390,Earth Smilodon,TG-3390,Emissary Panda,BRONZE UNION,APT27,Iron Tiger,LuckyMouse\\n\\nDescription\\n\\nThreat Group-3390 is a Chinese threat group that has extensively used strategic Web compromises to target victims.(Citation: Dell TG-3390) The group has been active since at least 2010 and has targeted organizations in the aerospace, government, defense, technology, energy, manufacturing and gambling/betting sectors.(Citation: SecureWorks BRONZE UNION June 2017)(Citation: Securelist LuckyMouse June 2018)(Citation: Trend Micro DRBControl February 2020)\\n\\nTechniques Used'),\n",
       " Document(metadata={'source': 'data\\\\documents\\\\Darkhotel.md', 'start_index': 0}, page_content=\"Darkhotel - G0012\\n\\nCreated: 2017-05-31T21:31:50.624Z\\n\\nModified: 2024-01-08T20:27:56.707Z\\n\\nContributors: Harry Kim, CODEMIZE\\n\\nAliases\\n\\nDarkhotel,DUBNIUM,Zigzag Hail\\n\\nDescription\\n\\nDarkhotel is a suspected South Korean threat group that has targeted victims primarily in East Asia since at least 2004. The group's name is based on cyber espionage operations conducted via hotel Internet networks against traveling executives and other select guests. Darkhotel has also conducted spearphishing campaigns and infected victims through peer-to-peer and file sharing networks.(Citation: Kaspersky Darkhotel)(Citation: Securelist Darkhotel Aug 2015)(Citation: Microsoft Digital Defense FY20 Sept 2020)\\n\\nTechniques Used\"),\n",
       " Document(metadata={'source': 'data\\\\documents\\\\admin@338.md', 'start_index': 0}, page_content='admin@338 - G0018\\n\\nCreated: 2017-05-31T21:31:53.579Z\\n\\nModified: 2020-03-18T19:54:59.120Z\\n\\nContributors: Tatsuya Daitoku, Cyber Defense Institute, Inc.\\n\\nAliases\\n\\nadmin@338\\n\\nDescription\\n\\nadmin@338 is a China-based cyber threat group. It has previously used newsworthy events as lures to deliver malware and has primarily targeted organizations involved in financial, economic, and trade policy, typically using publicly available RATs such as PoisonIvy, as well as some non-public backdoors. (Citation: FireEye admin@338)\\n\\nTechniques Used\\n\\nMatrix Domain Platform Technique ID Technique Name Use [\\'enterprise-attack\\'] enterprise-attack macOS,Windows,Linux T1566.001 Spearphishing Attachment admin@338 has sent emails with malicious Microsoft Office documents attached.(Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows,Network T1016 System Network Configuration Discovery admin@338 actors used the following command after exploiting a machine with LOWBALL malware to acquire information about local networks: ipconfig /all >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows,Containers T1036.005 Match Legitimate Name or Location admin@338 actors used the following command to rename one of their tools to a benign file name: ren \"%temp%\\\\upload\" audiodg.exe (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows,Network T1083 File and Directory Discovery admin@338 actors used the following commands after exploiting a machine with LOWBALL malware to obtain information about files and directories: dir c:\\\\ >> %temp%\\\\download dir \"c:\\\\Documents and Settings\" >> %temp%\\\\download dir \"c:\\\\Program Files\\\\\" >> %temp%\\\\download dir d:\\\\ >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows T1069.001 Local Groups admin@338 actors used the following command following exploitation of a machine with LOWBALL malware to list local groups: net localgroup administrator >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Windows,IaaS,Linux,macOS,Network T1049 System Network Connections Discovery admin@338 actors used the following command following exploitation of a machine with LOWBALL malware to display network connections: netstat -ano >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows T1087.001 Local Account admin@338 actors used the following commands following exploitation of a machine with LOWBALL malware to enumerate user accounts: net user >> %temp%\\\\download net user /domain >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,Windows,macOS T1203 Exploitation for Client Execution admin@338 has exploited client software vulnerabilities for execution, such as Microsoft Word CVE-2012-0158.(Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Windows,macOS,Linux T1007 System Service Discovery admin@338 actors used the following command following exploitation of a machine with LOWBALL malware to obtain information about services: net start >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Linux,macOS,Windows T1204.002 Malicious File admin@338 has attempted to get victims to launch malicious Microsoft Word attachments delivered via spearphishing emails.(Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Windows,IaaS,Linux,macOS,Network T1082 System Information Discovery admin@338 actors used the following commands after exploiting a machine with LOWBALL malware to obtain information about the OS: ver >> %temp%\\\\download systeminfo >> %temp%\\\\download (Citation: FireEye admin@338) [\\'enterprise-attack\\'] enterprise-attack Windows T1059.003 Windows Command Shell Following exploitation with LOWBALL malware, admin@338 actors created a file containing a list of commands to be executed on the compromised computer.(Citation: FireEye admin@338)')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as well as messaging services (such as WhatsApp) to spearphish victims.(Citation: SecureWorks Mia Ash July 2017)(Citation: Microsoft Phosphorus Mar 2019)(Citation: ClearSky Kittens Back 3 August 2020) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows T1560.001 Archive via Utility Magic Hound has used gzip to archive dumped LSASS process memory and RAR to stage and compress local folders.(Citation: FireEye APT35 2018)(Citation: DFIR Report APT35 ProxyShell March 2022)(Citation: DFIR Phosphorus November 2021) ['enterprise-attack'] enterprise-attack PRE T1585.001 Social Media Accounts Magic Hound has created fake LinkedIn and other social media accounts to contact targets and convince them--through messages and voice communications--to open malicious links.(Citation: ClearSky Kittens Back 3 August 2020) ['enterprise-attack'] enterprise-attack macOS,Windows,Linux T1564.003 Hidden Window Magic Hound malware has a function to determine whether the C2 server wishes to execute the newly dropped file in a hidden window.(Citation: Unit 42 Magic Hound Feb 2017) ['enterprise-attack'] enterprise-attack Windows,Office 365,IaaS,Linux,macOS,Containers,Network T1562 Impair Defenses Magic Hound has disabled LSA protection on compromised hosts using \"reg\" add HKLM\\SYSTEM\\CurrentControlSet\\Control\\LSA /v RunAsPPL /t REG_DWORD /d 0 /f .(Citation: DFIR Report APT35 ProxyShell March 2022) ['enterprise-attack'] enterprise-attack Linux,macOS,Windows,Network T1005 Data from Local System Magic Hound has used a web shell to exfiltrate a ZIP file containing a dump of LSASS memory on a compromised machine.(Citation: DFIR Report APT35 ProxyShell March 2022)(Citation: DFIR Phosphorus November 2021) ['enterprise-attack'] enterprise-attack Windows T1047 Windows Management Instrumentation Magic Hound has used a tool to run cmd /c wmic computersystem get domain for discovery.(Citation: DFIR Report APT35 ProxyShell March 2022) ['enterprise-attack'] enterprise-attack PRE T1583.006 Web Services Magic Hound has acquired Amazon S3 buckets to use in C2.(Citation: Check Point APT35 CharmPower January 2022) ['enterprise-attack'] enterprise-attack Windows,Linux,macOS,SaaS T1189 Drive-by Compromise Magic Hound has conducted watering-hole attacks through media and magazine websites.(Citation: ClearSky Kittens Back 3 August 2020)\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(relevant_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. Enable Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Database as a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Initialze LLM Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo-0125\", openai_api_key=openai_api_key, temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate the Retriever into a Question-Answering chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a Threat Intelligence assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. Initialize Conversation with Context / Relevant Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What threat actor sends text messages over social media to their targets?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Magic Hound is the threat actor that sends text messages over social media to their targets. They have created fake LinkedIn and other social media accounts to contact targets and convince them to open malicious links through messages and voice communications. (Citation: ClearSky Kittens Back 3 August 2020)'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": query})\n",
    "response[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
