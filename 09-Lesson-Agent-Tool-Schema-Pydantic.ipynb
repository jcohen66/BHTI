{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8: 9 - Anatomy of an AI Agent - From Tool to Function Call Format with Pydantic\n",
    "---------------------------------------------------------------------------------\n",
    "In this lesson, we will streamline the process of converting Python function signatures to OpenAI Function Calling format using Pydantic models. By leveraging the [model_json_schema()](https://docs.pydantic.dev/latest/concepts/json_schema/) method provided by Pydantic, we can generate JSON schemas compliant with JSON Schema Draft 2020-12 and OpenAPI Specification v3.1.0. This approach simplifies the creation of function signatures for OpenAI's Function Calling, enabling seamless tool execution. We will then proceed with the execution process using these validated and formatted tool arguments.\n",
    "\n",
    "## Objectives\n",
    "* Simplify the conversion of Python function signatures to OpenAI Function Calling format using Pydantic.\n",
    "* Understand how to generate JSON schemas from Pydantic models.\n",
    "* Integrate these JSON schemas into the tool execution process.\n",
    "* Validate and execute tools with the AI Agent using the generated schemas.\n",
    "\n",
    "## What this session covers:\n",
    "* Defining the current agent structure, including the LLM Client and short-term memory.\n",
    "* Creating Pydantic models for tool argument validation.\n",
    "* Generating JSON schemas from Pydantic models using model_json_schema().\n",
    "* Converting these JSON schemas to OpenAI Function Calling format.\n",
    "* Integrating the schemas into the AI Agent for tool execution.\n",
    "* Initializing and testing the AI Agent with simplified tool execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Current Agent Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "import openai\n",
    "\n",
    "class OpenAIChatCompletion:\n",
    "    \"\"\"Interacts with OpenAI's API for chat completions.\"\"\"\n",
    "    def __init__(self, model: str, api_key: str = None, base_url: str = None):\n",
    "        self.client = openai.OpenAI(api_key=api_key, base_url=base_url)\n",
    "        self.model = model\n",
    "\n",
    "    def generate(self, messages: List[str], tools: List[Dict[str, Any]] = None, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Generates a response from OpenAI's API.\"\"\"\n",
    "        params = {'messages': messages, 'model': self.model, 'tools': tools, **kwargs}\n",
    "        response = self.client.chat.completions.create(**params)\n",
    "        return response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class ChatMessageMemory:\n",
    "    \"\"\"Manages conversation context.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.messages = []\n",
    "    \n",
    "    def add_message(self, message: Dict):\n",
    "        \"\"\"Add a message to memory.\"\"\"\n",
    "        self.messages.append(message)\n",
    "    \n",
    "    def add_messages(self, messages: List[Dict]):\n",
    "        \"\"\"Add multiple messages to memory.\"\"\"\n",
    "        for message in messages:\n",
    "            self.add_message(message)\n",
    "    \n",
    "    def get_messages(self) -> List[Dict]:\n",
    "        \"\"\"Retrieve all messages.\"\"\"\n",
    "        return self.messages.copy()\n",
    "    \n",
    "    def reset_memory(self):\n",
    "        \"\"\"Clear all messages.\"\"\"\n",
    "        self.messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"Integrates LLM client, tools, and memory.\"\"\"\n",
    "    def __init__(self, llm_client, system_message: Dict[str, str], tools=None):\n",
    "        self.llm_client = llm_client\n",
    "        self.tools = tools\n",
    "        self.memory = ChatMessageMemory()\n",
    "        self.system_message = system_message\n",
    "\n",
    "    def run(self, user_message: Dict[str, str]):\n",
    "        self.memory.add_message(user_message)\n",
    "        chat_history = [self.system_message] + self.memory.get_messages()\n",
    "        response = self.llm_client.generate(chat_history, tools=self.tools)\n",
    "        self.memory.add_message(response)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Dummy Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Gets weather information.\"\"\"\n",
    "    temperature = random.randint(60, 80)\n",
    "    return f\"{location}: {temperature}F.\"\n",
    "\n",
    "def jump(distance: str) -> str:\n",
    "    \"\"\"Jumps a specific distance.\"\"\"\n",
    "    return f\"I jumped the following distance {distance}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tool Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetWeatherSchema(BaseModel):\n",
    "    \"\"\"Get weather information based on location.\"\"\"\n",
    "    location: str = Field(description=\"Location to get weather for\")\n",
    "\n",
    "class JumpSchema(BaseModel):\n",
    "    \"\"\"Jump a specific distance\"\"\"\n",
    "    distance: str = Field(description=\"Specific distance to jump for\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Schemas to OpenAI Function Calling Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_weather_func_dict = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Get weather information based on location.',\n",
    "        'parameters': {\n",
    "            'properties': {'location': {'type': 'string'}},\n",
    "            'required': ['location'],\n",
    "            'type': 'object'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "jump_func_dict = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'jump',\n",
    "        'description': 'Jump a specific distance.',\n",
    "        'parameters': {\n",
    "            'properties': {'distance': {'type': 'string'}},\n",
    "            'required': ['distance'],\n",
    "            'type': 'object'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [get_weather_func_dict, jump_func_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pydantic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "def to_openai_function_call_definition(name: str, model: BaseModel):\n",
    "    schema_dict = model.model_json_schema()\n",
    "    description = schema_dict.pop(\"description\", \"No description provided\")\n",
    "    schema_dict.pop(\"title\", None)  # Remove the title field to exclude the model name\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": name,\n",
    "            \"description\": description,\n",
    "            \"parameters\": schema_dict\n",
    "        }\n",
    "    }\n",
    "\n",
    "get_weather_func_dict = to_openai_function_call_definition(\"get_weather\", GetWeatherSchema)\n",
    "jump_func_dict = to_openai_function_call_definition(\"jump\", JumpSchema)\n",
    "\n",
    "tools = [get_weather_func_dict, jump_func_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_weather',\n",
       "  'description': 'Get weather information based on location.',\n",
       "  'parameters': {'properties': {'location': {'description': 'Location to get weather for',\n",
       "     'title': 'Location',\n",
       "     'type': 'string'}},\n",
       "   'required': ['location'],\n",
       "   'type': 'object'}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "get_weather_func_dict = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_weather',\n",
    "        'description': 'Get weather information based on location.',\n",
    "        'parameters': {\n",
    "            'properties': {'location': {'type': 'string'}},\n",
    "            'required': ['location'],\n",
    "            'type': 'object'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "tools[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API from environment variable\n",
    "# import os\n",
    "# api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "api_key=\"\"\n",
    "\n",
    "client = OpenAIChatCompletion(\n",
    "    base_url='https://api.openai.com/v1',\n",
    "    model='gpt-4',\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define System messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the system message\n",
    "system_message = {\"role\": \"system\", \"content\": \"You are a weather assistant.\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Agent with the LLM client, system message, and tools\n",
    "agent = Agent(llm_client=client, system_message=system_message, tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a User Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_140RrQ72jVF3kMjQTiqgYpih', function=Function(arguments='{\\n  \"location\": \"Virginia\"\\n}', name='get_weather'), type='function')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a user message\n",
    "user_message = {\"role\": \"user\", \"content\": \"What is the weather in Virginia?\"}\n",
    "\n",
    "# Generate a response using the agent\n",
    "response = agent.run(user_message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': None,\n",
       " 'role': 'assistant',\n",
       " 'tool_calls': [{'id': 'call_140RrQ72jVF3kMjQTiqgYpih',\n",
       "   'function': {'arguments': '{\\n  \"location\": \"Virginia\"\\n}',\n",
       "    'name': 'get_weather'},\n",
       "   'type': 'function'}]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Tool Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"location\": \"Virginia\"\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = response.tool_calls[0]\n",
    "tool_arguments_json = tool_response.function.arguments\n",
    "tool_arguments_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Function Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Tool Arguments - JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetWeatherSchema(location='Virginia')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_model = GetWeatherSchema.model_validate_json(tool_arguments_json)\n",
    "response_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Virginia'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_arguments_dict = response_model.model_dump()\n",
    "tool_arguments_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Virginia: 75F.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather(**tool_arguments_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
